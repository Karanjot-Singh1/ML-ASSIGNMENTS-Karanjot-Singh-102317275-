{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Lab Assignment 6 : SVM\n",
        "\n",
        "Machine Learning (UML501)\n",
        "\n",
        "KRISH KHAJURIA(102317023)"
      ],
      "metadata": {
        "id": "Ey6-ozm0F3pN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) The Iris dataset is a classic example for demonstrating classification algorithms. It consists of 150 samples of iris flowers belonging to three species: Setosa, Versicolor, and Virginica, with four input features (sepal and petal length/width). Use SVC from sklearn.svm on the Iris dataset and follow the steps below:\n",
        "a) Load the dataset and perform train–test split (80:20).\n",
        "b) Train three different SVM models using the following kernels:\n",
        "Linear, Polynomial (degree=3), RBF\n",
        "c) Evaluate each model using:\n",
        "• Accuracy\n",
        "• Precision\n",
        "• Recall\n",
        "• F1-Score\n",
        "d) Display the confusion matrix for each kernel.\n",
        "e) Identify which kernel performs the best and why."
      ],
      "metadata": {
        "id": "lfakbjByGCgm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-b_FDBCFvmF",
        "outputId": "9aed9cb1-3dd4-4f8c-ea34-0548032ff8d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Kernel: linear\n",
            "Accuracy : 0.9666666666666667\n",
            "Precision: 0.9696969696969697\n",
            "Recall   : 0.9666666666666667\n",
            "F1-score : 0.9665831244778613\n",
            "Confusion matrix:\n",
            " [[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  1  9]]\n",
            "\n",
            "Kernel: poly (3)\n",
            "Accuracy : 0.9666666666666667\n",
            "Precision: 0.9696969696969697\n",
            "Recall   : 0.9666666666666667\n",
            "F1-score : 0.9665831244778613\n",
            "Confusion matrix:\n",
            " [[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  1  9]]\n",
            "\n",
            "Kernel: rbf\n",
            "Accuracy : 0.9666666666666667\n",
            "Precision: 0.9696969696969697\n",
            "Recall   : 0.9666666666666667\n",
            "F1-score : 0.9665831244778613\n",
            "Confusion matrix:\n",
            " [[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  1  9]]\n",
            "\n",
            "Scores table:\n",
            "              acc      prec       rec        f1\n",
            "linear  0.966667  0.969697  0.966667  0.966583\n",
            "poly3   0.966667  0.969697  0.966667  0.966583\n",
            "rbf     0.966667  0.969697  0.966667  0.966583\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "# a) load and split (80:20)\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
        "\n",
        "# helper to train and evaluate\n",
        "def fit_check(kern_name, model):\n",
        "    model.fit(X_tr, y_tr)\n",
        "    y_pr = model.predict(X_te)\n",
        "\n",
        "    acc = accuracy_score(y_te, y_pr)\n",
        "    pre = precision_score(y_te, y_pr, average=\"macro\")\n",
        "    rec = recall_score(y_te, y_pr, average=\"macro\")\n",
        "    f1  = f1_score(y_te, y_pr, average=\"macro\")\n",
        "    cm  = confusion_matrix(y_te, y_pr)\n",
        "\n",
        "    print(f\"\\nKernel: {kern_name}\")\n",
        "    print(\"Accuracy :\", acc)\n",
        "    print(\"Precision:\", pre)\n",
        "    print(\"Recall   :\", rec)\n",
        "    print(\"F1-score :\", f1)\n",
        "    print(\"Confusion matrix:\\n\", cm)\n",
        "\n",
        "    return acc, pre, rec, f1\n",
        "\n",
        "# b) 3 SVM models\n",
        "svc_lin = SVC(kernel=\"linear\", random_state=1)\n",
        "svc_poly = SVC(kernel=\"poly\", degree=3, random_state=1)\n",
        "svc_rbf = SVC(kernel=\"rbf\", random_state=1)\n",
        "\n",
        "res = {}\n",
        "res[\"linear\"] = fit_check(\"linear\", svc_lin)\n",
        "res[\"poly3\"] = fit_check(\"poly (3)\", svc_poly)\n",
        "res[\"rbf\"]   = fit_check(\"rbf\", svc_rbf)\n",
        "\n",
        "# put scores in a small table\n",
        "cols = [\"acc\", \"prec\", \"rec\", \"f1\"]\n",
        "df_res = pd.DataFrame(res, index=cols).T\n",
        "print(\"\\nScores table:\\n\", df_res)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) SVM models are highly sensitive to the scale of input features. When features have different ranges, the algorithm may incorrectly assign higher importance to variables with larger magnitudes, affecting the placement of the separating hyperplane. Feature scaling ensures that all attributes contribute equally to distance-based computations, which is especially crucial for kernels like RBF or polynomial.\n",
        "A) Use the Breast Cancer dataset from sklearn.datasets.load_breast_cancer.\n",
        "B) Train an SVM (RBF kernel) model with and without feature scaling (StandardScaler). Compare both results using:\n",
        "• Training accuracy\n",
        "• Testing accuracy\n",
        "C) Discuss the effect of feature scaling on SVM performance."
      ],
      "metadata": {
        "id": "mCi0G65mGEKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# load data\n",
        "cancer = load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
        "\n",
        "# model 1: RBF SVM WITHOUT scaling\n",
        "svm_raw = SVC(kernel=\"rbf\", gamma=\"scale\", random_state=1)\n",
        "svm_raw.fit(X_tr, y_tr)\n",
        "\n",
        "y_tr_raw = svm_raw.predict(X_tr)\n",
        "y_te_raw = svm_raw.predict(X_te)\n",
        "\n",
        "acc_tr_raw = accuracy_score(y_tr, y_tr_raw)\n",
        "acc_te_raw = accuracy_score(y_te, y_te_raw)\n",
        "\n",
        "print(\"Without scaling - train acc:\", acc_tr_raw)\n",
        "print(\"Without scaling - test  acc:\", acc_te_raw)\n",
        "\n",
        "# model 2: RBF SVM WITH StandardScaler\n",
        "svm_scaled = Pipeline([\n",
        "    (\"sc\", StandardScaler()),\n",
        "    (\"svm\", SVC(kernel=\"rbf\", gamma=\"scale\", random_state=1))\n",
        "])\n",
        "\n",
        "svm_scaled.fit(X_tr, y_tr)\n",
        "\n",
        "y_tr_sc = svm_scaled.predict(X_tr)\n",
        "y_te_sc = svm_scaled.predict(X_te)\n",
        "\n",
        "acc_tr_sc = accuracy_score(y_tr, y_tr_sc)\n",
        "acc_te_sc = accuracy_score(y_te, y_te_sc)\n",
        "\n",
        "print(\"\\nWith scaling - train acc:\", acc_tr_sc)\n",
        "print(\"With scaling - test  acc:\", acc_te_sc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvlI4zmfGMPo",
        "outputId": "4b84b597-0e43-414a-e0dc-c8b0d6abe6d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear R2: 0.1487 MSE: 184380.2415\n",
            "Ridge(0.5748) R2: 0.2158 MSE: 169859.6296\n",
            "Lasso(0.5748) R2: 0.2091 MSE: 171309.4014\n"
          ]
        }
      ]
    }
  ]
}