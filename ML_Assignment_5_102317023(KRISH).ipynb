{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Lab Assignment 5\n",
        "Machine Learning (UML501)\n",
        "\n",
        "KRISH KHAJURIA(102317023)"
      ],
      "metadata": {
        "id": "Ey6-ozm0F3pN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q\n",
        "1\n",
        "(Based on Step-by-Step Implementation of Ridge Regression using Gradient\n",
        "Descent Optimization)\n",
        "Generate a dataset with atleast seven highly correlated columns and a target variable.\n",
        "Implement Ridge Regression using Gradient Descent Optimization. Take different\n",
        "values of learning rate (such as 0.0001,0.001,0.01,0.1,1,10) and regularization\n",
        "parameter (10-15,10-10,10-5,10- 3,0,1,10,20). Choose the best parameters for which ridge\n",
        "regression cost function is minimum and R2_score is maximum."
      ],
      "metadata": {
        "id": "lfakbjByGCgm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-b_FDBCFvmF",
        "outputId": "6a48b6d3-6b71-45b9-ff1c-d2f83c89b383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: {'lr': 0.1, 'lam': 0.001, 'r2': 0.9890421683608686, 'cost': np.float64(0.13372750464682248)}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np, pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "np.random.seed(5)\n",
        "n = 1200\n",
        "x = np.random.randn(n, 7)\n",
        "true_w = np.array([2.4, -1.8, 3.1, 0.7, 0.0, 1.0, -2.0])\n",
        "y = x @ true_w + np.random.normal(0, 0.5, n)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=4)\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)\n",
        "\n",
        "def ridge_gd(x, y, lr, lam, steps):\n",
        "    n, p = x.shape\n",
        "    x = np.c_[np.ones((n, 1)), x]\n",
        "    w = np.zeros(p + 1)\n",
        "    for _ in range(steps):\n",
        "        y_hat = x @ w\n",
        "        e = y_hat - y\n",
        "        g = (x.T @ e) / n\n",
        "        g[1:] += lam * w[1:]\n",
        "        w -= lr * g\n",
        "    return w\n",
        "\n",
        "def ridge_cost(x, y, w, lam):\n",
        "    n = x.shape[0]\n",
        "    x = np.c_[np.ones((n, 1)), x]\n",
        "    e = x @ w - y\n",
        "    return 0.5 * np.mean(e ** 2) + 0.5 * lam * np.sum(w[1:] ** 2)\n",
        "\n",
        "best = None\n",
        "for lr in [1e-4, 1e-3, 1e-2, 0.1]:\n",
        "    for lam in [0, 0.001, 0.01, 0.1, 1, 10]:\n",
        "        w = ridge_gd(x_train, y_train, lr, lam, 3000)\n",
        "        cost = ridge_cost(x_train, y_train, w, lam)\n",
        "        y_pred = np.c_[np.ones((x_test.shape[0], 1)), x_test] @ w\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        if best is None or r2 > best['r2']:\n",
        "            best = dict(lr=lr, lam=lam, r2=r2, cost=cost)\n",
        "\n",
        "print(\"Best:\", best)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q\n",
        "2\n",
        "Load the Hitters dataset from the following link\n",
        "https://drive.google.com/file/d/1qzCKF6JKKMB0p7ul_lLy8tdmRk3vE_bG/view?usp=sharing\n",
        "Pre-process the data (null values, noise, categorical to numerical encoding)\n",
        "Separate input and output features and perform scaling\n",
        "Fit a Linear, Ridge (use regularization parameter as 0.5748), and LASSO (use\n",
        "regularization parameter as 0.5748) regression function on the dataset.\n",
        "Evaluate the performance of each trained model on test set. Which model\n",
        "performs the best and Why?"
      ],
      "metadata": {
        "id": "mCi0G65mGEKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/Hitters.csv')\n",
        "df = df.dropna()\n",
        "y = df.select_dtypes(include=[np.number]).iloc[:, -1]\n",
        "x = df.drop(columns=[y.name])\n",
        "x = pd.get_dummies(x, drop_first=True)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=11)\n",
        "sc = StandardScaler(with_mean=False)\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)\n",
        "\n",
        "lin = LinearRegression().fit(x_train, y_train)\n",
        "rig = Ridge(alpha=0.5748).fit(x_train, y_train)\n",
        "las = Lasso(alpha=0.5748, max_iter=20000).fit(x_train, y_train)\n",
        "\n",
        "models = {\n",
        "    \"Linear\": lin,\n",
        "    \"Ridge(0.5748)\": rig,\n",
        "    \"Lasso(0.5748)\": las\n",
        "}\n",
        "\n",
        "for name, m in models.items():\n",
        "    p = m.predict(x_test)\n",
        "    print(name, \"R2:\", round(r2_score(y_test, p), 4), \"MSE:\", round(mean_squared_error(y_test, p), 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvlI4zmfGMPo",
        "outputId": "4b84b597-0e43-414a-e0dc-c8b0d6abe6d0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear R2: 0.1487 MSE: 184380.2415\n",
            "Ridge(0.5748) R2: 0.2158 MSE: 169859.6296\n",
            "Lasso(0.5748) R2: 0.2091 MSE: 171309.4014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q\n",
        "3\n",
        "Cross Validation for Ridge and Lasso Regression\n",
        "Explore Ridge Cross Validation (RidgeCV) and Lasso Cross Validation (LassoCV)\n",
        "function of Python. Implement both on Boston House Prediction Dataset (load_boston\n",
        "dataset from sklearn.datasets)."
      ],
      "metadata": {
        "id": "0FMOUHyjGHtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import RidgeCV, LassoCV\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "data = fetch_california_housing()\n",
        "x = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=5)\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)\n",
        "\n",
        "rid = RidgeCV(alphas=np.logspace(-4, 3, 30), cv=5).fit(x_train, y_train)\n",
        "las = LassoCV(alphas=np.logspace(-4, 1, 30), cv=5, max_iter=30000).fit(x_train, y_train)\n",
        "\n",
        "pred_r = rid.predict(x_test)\n",
        "pred_l = las.predict(x_test)\n",
        "\n",
        "print(\"RidgeCV α:\", rid.alpha_, \"R2:\", round(r2_score(y_test, pred_r), 4), \"MSE:\", round(mean_squared_error(y_test, pred_r), 4))\n",
        "print(\"LassoCV α:\", las.alpha_, \"R2:\", round(r2_score(y_test, pred_l), 4), \"MSE:\", round(mean_squared_error(y_test, pred_l), 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgQUFwJmGMys",
        "outputId": "8f4e8e1e-0352-4335-f35f-eb29c5f0b935"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RidgeCV α: 35.622478902624444 R2: 0.6101 MSE: 0.5338\n",
            "LassoCV α: 0.003562247890262444 R2: 0.6102 MSE: 0.5336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q\n",
        "4\n",
        "Multiclass Logistic Regression: Implement Multiclass Logistic Regression (step-by step)\n",
        "on Iris dataset using one vs. rest strategy?"
      ],
      "metadata": {
        "id": "5w1x6LesGJe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "d = load_iris()\n",
        "x = d.data\n",
        "y = d.target\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=4, stratify=y)\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)\n",
        "\n",
        "def sig(z): return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def gd(x, y, lr=0.1, lam=0.0, steps=4000):\n",
        "    n, p = x.shape\n",
        "    x = np.c_[np.ones((n, 1)), x]\n",
        "    w = np.zeros(p + 1)\n",
        "    for _ in range(steps):\n",
        "        z = x @ w\n",
        "        p1 = sig(z)\n",
        "        g = (x.T @ (p1 - y)) / n\n",
        "        g[1:] += lam * w[1:]\n",
        "        w -= lr * g\n",
        "    return w\n",
        "\n",
        "classes = np.unique(y_train)\n",
        "w_all = []\n",
        "for c in classes:\n",
        "    y_bin = (y_train == c).astype(int)\n",
        "    w_all.append(gd(x_train, y_bin, lr=0.2, steps=5000))\n",
        "W = np.vstack(w_all)\n",
        "\n",
        "def predict(x, W):\n",
        "    x = np.c_[np.ones((x.shape[0], 1)), x]\n",
        "    return np.argmax(sig(x @ W.T), axis=1)\n",
        "\n",
        "pred = predict(x_test, W)\n",
        "print(\"Accuracy:\", round(accuracy_score(y_test, pred), 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wpjUfQCGNVS",
        "outputId": "2335daa7-ce64-4107-c56a-b6dc2e4bc0d2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9474\n"
          ]
        }
      ]
    }
  ]
}